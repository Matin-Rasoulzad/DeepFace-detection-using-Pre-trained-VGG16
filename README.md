# DeepFace Tracker using Pre-trained VGG16

This project is a personalized deep learning application that uses the VGG16 model to track head movements. By leveraging a pre-trained VGG16 convolutional neural network and fine-tuning it with 90 self-captured images, the model has been customized to recognize and follow the user's unique facial features. This approach ensures precise and reliable tracking tailored specifically to the user's face.  

The primary aim of the project is to monitor and track head movements in real-time, providing a foundation for applications like gesture-based controls, virtual reality, or accessibility tools. By combining the power of pre-trained models with personalization, this project demonstrates the potential of deep learning in creating adaptable and highly accurate tracking systems.  

## Ø±Ø¯ÛŒØ§Ø¨ Ø¹Ù…Ù‚ Ú†Ù‡Ø±Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² VGG16 ğŸ¥  

Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚ Ø§Ø³Øª Ú©Ù‡ Ø§Ø² Ù…Ø¯Ù„ VGG16 Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø­Ø±Ú©Ø§Øª Ø³Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø§ Ø¨Ù‡Ø±Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ VGG16 Ùˆ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ø¢Ù† Ø¨Ø§ Û¹Û° ØªØµÙˆÛŒØ± Ø´Ø®ØµÛŒØŒ Ù…Ø¯Ù„ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø§Ø®ØªØµØ§ØµÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ùˆ Ø¯Ù†Ø¨Ø§Ù„ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ú†Ù‡Ø±Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø³ÙØ§Ø±Ø´ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¯Ù‚Øª Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø± Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ù¾Ø§ÛŒÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹ Ù…Ø§Ù†Ù†Ø¯ Ú©Ù†ØªØ±Ù„ Ø¨Ø§ Ø­Ø±Ú©Ø§ØªØŒ ÙˆØ§Ù‚Ø¹ÛŒØª Ù…Ø¬Ø§Ø²ÛŒ Ùˆ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø³ØªØ±Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.  


![example](docs/Banner.png)
