# DeepFace Tracker using Pre-trained VGG16

This project is a personalized deep learning application that uses the VGG16 model to track head movements. By leveraging a pre-trained VGG16 convolutional neural network and fine-tuning it with 90 self-captured images, the model has been customized to recognize and follow the user's unique facial features. This approach ensures precise and reliable tracking tailored specifically to the user's face.  

The primary aim of the project is to monitor and track head movements in real-time, providing a foundation for applications like gesture-based controls, virtual reality, or accessibility tools. By combining the power of pre-trained models with personalization, this project demonstrates the potential of deep learning in creating adaptable and highly accurate tracking systems.   

Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒÚ© Ù…Ø¯Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø­Ø±Ú©Ø§Øª Ø³Ø± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ù‚ÛŒÙ‚ Ø¯Ù†Ø¨Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ VGG16 Ùˆ fine-tune Ú©Ø±Ø¯Ù† Ø¢Ù† Ø¨Ø§ 90 ØªØµÙˆÛŒØ± Ø´Ø®ØµÛŒØŒ Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡ Ùˆ Ø­Ø±Ú©Ø§Øª Ø´Ù…Ø§ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.

![example](Docs/Banner.png)


## **ğŸ”¸Note:** This project is work in progress and indeed not a final model.

![example](Docs/Final-output.png)
